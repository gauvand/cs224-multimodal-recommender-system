{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Processing lyrics \n",
    "Create lyric embeddings for every file in `processed_lyrics`"
   ],
   "id": "a16af6264ca5ea4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!cd ",
   "id": "708b523cf7a14f34"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T02:21:01.207423Z",
     "start_time": "2024-11-04T02:21:00.487528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm"
   ],
   "id": "75148333bafd929e",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T01:51:08.612504Z",
     "start_time": "2024-11-04T01:51:08.609485Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.empty_cache()",
   "id": "fbb6e1625707f3ff",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T02:49:25.415602Z",
     "start_time": "2024-11-05T02:49:25.412971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# setting up directories\n",
    "project_home_dir = 'D:/Projects/cs224-multimodal-recommender-system'"
   ],
   "id": "8d71b3b07a3f754f",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T01:51:18.901783Z",
     "start_time": "2024-11-04T01:51:18.899756Z"
    }
   },
   "cell_type": "code",
   "source": "# !tar -xvzf {os.path.join(project_home_dir, 'datasets/m4a-onion-kaggle/processed_lyrics.tar.gz')} -C {os.path.join(project_home_dir, 'datasets/m4a-onion-kaggle/')}",
   "id": "dd1caae05d358e59",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T02:16:10.668319Z",
     "start_time": "2024-11-04T02:03:58.217325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lyrics_dir = os.path.join(project_home_dir, 'datasets/m4a-onion-kaggle/processed_lyrics/')\n",
    "\n",
    "# Load pre-trained RoBERTa model and tokenizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaModel.from_pretrained('roberta-base').to(device)\n",
    "\n",
    "# Function to generate embeddings using mean pooling\n",
    "def generate_roberta_embedding(text):\n",
    "    if isinstance(text, str):\n",
    "        # Tokenize input text\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512, padding=True).to(device)\n",
    "        # Pass through RoBERTa model\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        mean_embedding = torch.mean(last_hidden_state, dim=1).squeeze()\n",
    "        return mean_embedding.cpu().numpy()\n",
    "\n",
    "    else:\n",
    "        return None\n",
    "data = []\n",
    "# Iterate through each file in the lyrics directory\n",
    "for filename in tqdm.tqdm(os.listdir(lyrics_dir)):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        track_id = filename.replace(\".txt\", \"\")\n",
    "        file_path = os.path.join(lyrics_dir, filename)\n",
    "        # Read the lyrics from the file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lyrics = file.read()\n",
    "        # Generate the embedding\n",
    "        embedding = generate_roberta_embedding(lyrics)\n",
    "        # Append the track ID and embedding to the data list\n",
    "        data.append({'track_id': track_id, 'lyrics_embedding': embedding})\n",
    "\n",
    "roberta_embedding_df = pd.DataFrame(data)"
   ],
   "id": "566bb7813c2f560b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/109269 [00:00<?, ?it/s]D:\\Miniconda\\envs\\ai\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:370: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "100%|██████████| 109269/109269 [12:11<00:00, 149.32it/s]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T02:19:33.186472Z",
     "start_time": "2024-11-04T02:19:31.685021Z"
    }
   },
   "cell_type": "code",
   "source": "roberta_embedding_df.to_parquet('D:\\\\Projects\\\\cs224-multimodal-recommender-system\\\\processed_data\\\\m4a-onion-kaggle\\\\roberta_embedding_lyrics.parquet')",
   "id": "18dd2fee911c29ef",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T02:30:46.878979Z",
     "start_time": "2024-11-04T02:21:20.120472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Load pre-trained Sentence Transformer model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "# Function to generate embeddings for the entire lyrics\n",
    "def generate_sentence_transformer_embedding(text):\n",
    "    # Generate embedding for the entire text\n",
    "    embedding = model.encode(text, convert_to_tensor=True, device=device)\n",
    "    return embedding.cpu().numpy()\n",
    "\n",
    "# Create a list to store track IDs and embeddings\n",
    "data = []\n",
    "\n",
    "# Iterate through each file in the lyrics directory\n",
    "for filename in tqdm.notebook.tqdm(os.listdir(lyrics_dir)):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        track_id = filename.replace(\".txt\", \"\")\n",
    "        file_path = os.path.join(lyrics_dir, filename)\n",
    "        # Read the lyrics from the file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lyrics = file.read()\n",
    "        # Generate the embedding\n",
    "        embedding = generate_sentence_transformer_embedding(lyrics)\n",
    "        # Append the track ID and embedding to the data list\n",
    "        data.append({'track_id': track_id, 'lyrics_embedding': embedding})\n",
    "\n",
    "# Create a DataFrame from the data list\n",
    "minilm_embedding_df = pd.DataFrame(data)"
   ],
   "id": "825db0b36ae96662",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gaurav Anand\\AppData\\Local\\Temp\\ipykernel_27548\\3096610804.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for filename in tqdm.tqdm_notebook(os.listdir(lyrics_dir)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/109269 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "592a46091b80439380028f60e9f9c1c9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "3bd09c6fea603750"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T02:30:48.904266Z",
     "start_time": "2024-11-04T02:30:48.893101Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.empty_cache()",
   "id": "91e6a44c900c0f7e",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T02:31:57.999194Z",
     "start_time": "2024-11-04T02:31:57.213324Z"
    }
   },
   "cell_type": "code",
   "source": "minilm_embedding_df.to_parquet('D:\\\\Projects\\\\cs224-multimodal-recommender-system\\\\processed_data\\\\m4a-onion-kaggle\\\\minilm_embedding_lyrics.parquet')",
   "id": "7ca428b5c325c1f1",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4405618dfb622907"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
